# streamprocessing-kafka-finlight-news-dashboard

# repo structure
news-stream-pipeline/
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ producer.py          # polls API â†’ sends to Kafka
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ stream_processor/
â”‚   â”œâ”€â”€ app.py               # Faust or Flink job
â”‚   â”œâ”€â”€ transformations.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ sinks/
â”‚   â”œâ”€â”€ sink_to_duckdb.py
â”‚   â”œâ”€â”€ sink_to_s3.py
â”‚   â””â”€â”€ schema.sql
â”œâ”€â”€ docker-compose.yml       # kafka, zookeeper, redpanda-console, duckdb container
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analytics.ipynb
â””â”€â”€ README.md

# News Stream Processing Pipeline
This repository contains a complete pipeline for ingesting, processing, and visualizing news articles using Apache Kafka and stream processing frameworks. The pipeline fetches news articles from a public API, processes them in real-time, and stores them for analysis and visualization.

ğŸ“¡ News API
   â”‚
   â–¼
ğŸ§µ Ingestion Service (Python)
   â”œâ”€â”€ Fetches new articles every X seconds
   â”œâ”€â”€ Sends each article as JSON event to Kafka topic `news_raw`
   â”‚
   â–¼
ğŸƒ Apache Kafka 
   â”œâ”€â”€ Topics: news_raw, news_clean, news_enriched
   â”‚
   â–¼
ğŸ”¥ Stream Processor
   â”œâ”€â”€ Option A: Apache Flink / Spark Structured Streaming
   â”œâ”€â”€ Option B: Faust / Kafka Streams (Python)
   â”œâ”€â”€ Cleans data, deduplicates, adds derived fields
   â”‚
   â–¼
ğŸª£ Sink / Data Lake
   â”œâ”€â”€ Writes Parquet to S3 / MinIO
   â”œâ”€â”€ Or loads to Postgres / DuckDB for analytics
   â”‚
   â–¼
ğŸ“Š Dashboard Layer
   â”œâ”€â”€ Superset / Grafana / Streamlit
   â””â”€â”€ Displays live counts, trends, top sources


